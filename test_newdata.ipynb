{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用新数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_utils import *\n",
    "mydevice = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "class create_test_data:\n",
    "    def __init__(self, non_overlap_data_path, num_test_samples=100) -> None:\n",
    "        if not os.path.exists(non_overlap_data_path):\n",
    "            raise ValueError(\"There is no nonoverlap data file\")\n",
    "        self.non_overlap_data_path = non_overlap_data_path\n",
    "        self.num_test_samples = num_test_samples\n",
    "        self.samples = None\n",
    "        # Open non-overlap data path to get a bunch of test samples\n",
    "        with open(self.non_overlap_data_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            random.shuffle(lines)\n",
    "            self.samples = lines[:self.num_test_samples]\n",
    "            \n",
    "        \n",
    "    def create_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'Ta+b=' .\n",
    "        The output should be correct answer and judgement\n",
    "        \"\"\"\n",
    "        with open(f'prompt.txt', 'w') as f2:\n",
    "            for line in self.samples:\n",
    "                prompt = line.split('=')[0]+'=\\n'\n",
    "                f2.write(prompt)\n",
    "                    \n",
    "    def create_add_noise_judge_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'a+b=c' and 'a+b=d', where 'd' means wrong answer\n",
    "        The output should be judgement\n",
    "        \"\"\"\n",
    "        with open('add_noise_judge_prompt.txt', 'w') as f3:\n",
    "            for line in self.samples:\n",
    "                # 取出表达式部分\n",
    "                prompt = line.split('T')[1].strip()\n",
    "                # prompt = prompt.split('=')[0].strip()\n",
    "                new_prompt = self.modify_result(prompt, random.randint(1, 9), 'noise_add')\n",
    "                f3.write(new_prompt + '?\\n')\n",
    "                \n",
    "    def create_extra_num_judge_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'a+b=c' and 'a+b=cd', where 'd' means extra number\n",
    "        The output should be judgement\n",
    "        \"\"\"\n",
    "        with open('extra_num_judge_prompt.txt', 'w') as f4:\n",
    "            for line in self.samples:\n",
    "                # 取出表达式部分\n",
    "                prompt = line.split('T')[1].strip()\n",
    "                # prompt = prompt.split('=')[0].strip()\n",
    "                new_prompt = self.modify_result(prompt, random.randint(1, 9), 'extra_num')\n",
    "                f4.write(new_prompt + '?\\n')\n",
    "\n",
    "    \n",
    "    def modify_result(self, expression, addend, mode):\n",
    "        # 使用正则表达式提取表达式中的数字\n",
    "        match = re.match(r'(\\d+)\\+(\\d+)=(\\d+)', expression)\n",
    "    \n",
    "        if match:\n",
    "            # 提取数字并计算新的结果\n",
    "            num1 = int(match.group(1))\n",
    "            num2 = int(match.group(2))\n",
    "            result = int(match.group(3))\n",
    "            num_digit = len(match.group(3).strip())\n",
    "            if mode == 'extra_num':\n",
    "                if random.uniform(0,1)>0.5 and random.uniform(0,1)<0.75:\n",
    "                    extra = random.randint(1, 9)\n",
    "                    new_expression = f\"F{num1}+{num2}={result}{extra}\"\n",
    "                elif random.uniform(0,1)>0.75:\n",
    "                    extra = random.randint(1, 9)\n",
    "                    new_expression = f\"F{num1}+{num2}={extra}{result}\"\n",
    "                else:\n",
    "                    new_expression = f\"T{num1}+{num2}={result}\"\n",
    "            elif mode == 'noise_add':\n",
    "                if random.uniform(0,1)>0.5:\n",
    "                    # 决定添加错误的位置\n",
    "                    wrong_loc = random.randint(0, num_digit)\n",
    "        \n",
    "                    new_result = result + addend * (10**wrong_loc)\n",
    "\n",
    "                    # 构建新的表达式\n",
    "                    new_expression = f\"F{num1}+{num2}={new_result}\"\n",
    "                else:\n",
    "                    new_expression = f\"T{num1}+{num2}={result}\"\n",
    "            \n",
    "            else:\n",
    "                return \"Invalid modify pattern\"\n",
    "        \n",
    "            return new_expression\n",
    "        else:\n",
    "            return \"Invalid expression format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlap_data_path = './data/get_data_with_label/train_3digit_bilabeled10000_nonoverlap.txt'\n",
    "num_examples = 10000\n",
    "new_creator = create_test_data(non_overlap_data_path, num_examples)\n",
    "new_creator.create_prompt()\n",
    "new_creator.create_extra_num_judge_prompt()\n",
    "new_creator.create_add_noise_judge_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.63M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(16, 384)\n",
       "    (wpe): Embedding(256, 384)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=16, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GPTConfig, GPT\n",
    "import torch\n",
    "\n",
    "# init from a model saved in a specific directory\n",
    "ckpt_path = 'ckpt_acc_bilabel(0.6p).pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=mydevice)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta from ./data/addition_bilabel/meta.pkl...\n"
     ]
    }
   ],
   "source": [
    "encode, decode = get_encode_decode('./data/addition_bilabel/meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20597.15it/s]\n",
      "100%|██████████| 81/81 [00:01<00:00, 52.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 9531/10000 (95.30999999999999%)\n",
      "accuracy of 10000 examples: 9532/10000 (95.32000000000001%)\n",
      "{'carry0': 95.96199524940617, 'carry1': 93.80505825518614, 'carry2': 96.03174603174604, 'carry3': 96.6903073286052}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.30999999999999,\n",
       " 95.32000000000001,\n",
       " {'carry0': 95.96199524940617,\n",
       "  'carry1': 93.80505825518614,\n",
       "  'carry2': 96.03174603174604,\n",
       "  'carry3': 96.6903073286052})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./prompt.txt',\n",
    "    'device': mydevice,\n",
    "    'temperature': 0.8\n",
    "}\n",
    "eval_addition_batch(config, model, ctx, encode, decode, judge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试extra number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./extra_num_judge_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 16871.84it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 198.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 9388/10000 (93.88%)\n",
      "No judging probability of 10000 examples: 0/10000 (0.0%)\n",
      "True Positive Examples: 4114/10000\n",
      "False Positive Examples: 89/10000\n",
      "True Negative Examples: 5274/10000\n",
      "False Negative Examples: 523/10000\n",
      "{'carry0': 93.58669833729216, 'carry1': 92.55470304063654, 'carry2': 94.38775510204081, 'carry3': 96.53270291568164}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.88,\n",
       " 0.0,\n",
       " {'carry0': 93.58669833729216,\n",
       "  'carry1': 92.55470304063654,\n",
       "  'carry2': 94.38775510204081,\n",
       "  'carry3': 96.53270291568164})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./extra_num_judge_prompt.txt',\n",
    "    'device': mydevice,\n",
    "}\n",
    "eval_judge_batch(config, model, ctx, encode, decode, max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试add_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./add_noise_judge_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 22073.09it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 192.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 6691/10000 (66.91%)\n",
      "No judging probability of 10000 examples: 0/10000 (0.0%)\n",
      "True Positive Examples: 4453/10000\n",
      "False Positive Examples: 2764/10000\n",
      "True Negative Examples: 2238/10000\n",
      "False Negative Examples: 545/10000\n",
      "{'carry0': 64.66745843230403, 'carry1': 65.70048309178745, 'carry2': 67.3469387755102, 'carry3': 72.02521670606778}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66.91,\n",
       " 0.0,\n",
       " {'carry0': 64.66745843230403,\n",
       "  'carry1': 65.70048309178745,\n",
       "  'carry2': 67.3469387755102,\n",
       "  'carry3': 72.02521670606778})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./add_noise_judge_prompt.txt',\n",
    "    'device': mydevice,\n",
    "}\n",
    "eval_judge_batch(config, model, ctx, encode, decode, max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新数据：20%positive + 80%negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "class create_test_data:\n",
    "    def __init__(self, non_overlap_data_path, num_test_samples=100) -> None:\n",
    "        if not os.path.exists(non_overlap_data_path):\n",
    "            raise ValueError(\"There is no nonoverlap data file\")\n",
    "        self.non_overlap_data_path = non_overlap_data_path\n",
    "        self.num_test_samples = num_test_samples\n",
    "        self.samples = None\n",
    "        # Open non-overlap data path to get a bunch of test samples\n",
    "        with open(self.non_overlap_data_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            random.shuffle(lines)\n",
    "            self.samples = lines[:self.num_test_samples]\n",
    "            \n",
    "        \n",
    "    def create_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'Ta+b=' .\n",
    "        The output should be correct answer and judgement\n",
    "        \"\"\"\n",
    "        with open(f'prompt.txt', 'w') as f2:\n",
    "            for line in self.samples:\n",
    "                prompt = line.split('=')[0]+'=\\n'\n",
    "                f2.write(prompt)\n",
    "                    \n",
    "    def create_add_noise_judge_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'a+b=c' and 'a+b=d', where 'd' means wrong answer\n",
    "        The output should be judgement\n",
    "        \"\"\"\n",
    "        with open('add_noise_judge_prompt.txt', 'w') as f3:\n",
    "            for line in self.samples:\n",
    "                # 取出表达式部分\n",
    "                prompt = line.split('T')[1].strip()\n",
    "                # prompt = prompt.split('=')[0].strip()\n",
    "                new_prompt = self.modify_result(prompt, random.randint(1, 9), 'noise_add')\n",
    "                f3.write(new_prompt + '?\\n')\n",
    "                \n",
    "    def create_extra_num_judge_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'a+b=c' and 'a+b=cd', where 'd' means extra number\n",
    "        The output should be judgement\n",
    "        \"\"\"\n",
    "        with open('extra_num_judge_prompt.txt', 'w') as f4:\n",
    "            for line in self.samples:\n",
    "                # 取出表达式部分\n",
    "                prompt = line.split('T')[1].strip()\n",
    "                # prompt = prompt.split('=')[0].strip()\n",
    "                new_prompt = self.modify_result(prompt, random.randint(1, 9), 'extra_num')\n",
    "                f4.write(new_prompt + '?\\n')\n",
    "\n",
    "    \n",
    "    def modify_result(self, expression, addend, mode):\n",
    "        # 使用正则表达式提取表达式中的数字\n",
    "        match = re.match(r'(\\d+)\\+(\\d+)=(\\d+)', expression)\n",
    "    \n",
    "        if match:\n",
    "            # 提取数字并计算新的结果\n",
    "            num1 = int(match.group(1))\n",
    "            num2 = int(match.group(2))\n",
    "            result = int(match.group(3))\n",
    "            num_digit = len(match.group(3).strip())\n",
    "            if mode == 'extra_num':\n",
    "                if random.uniform(0,1)>0.5 and random.uniform(0,1)<0.75:\n",
    "                    extra = random.randint(1, 9)\n",
    "                    new_expression = f\"F{num1}+{num2}={result}{extra}\"\n",
    "                elif random.uniform(0,1)>0.75:\n",
    "                    extra = random.randint(1, 9)\n",
    "                    new_expression = f\"F{num1}+{num2}={extra}{result}\"\n",
    "                else:\n",
    "                    new_expression = f\"T{num1}+{num2}={result}\"\n",
    "            elif mode == 'noise_add':\n",
    "                if random.uniform(0,1)>0.5:\n",
    "                    # 决定添加错误的位置\n",
    "                    wrong_loc = random.randint(0, num_digit)\n",
    "        \n",
    "                    new_result = result + addend * (10**wrong_loc)\n",
    "\n",
    "                    # 构建新的表达式\n",
    "                    new_expression = f\"F{num1}+{num2}={new_result}\"\n",
    "                else:\n",
    "                    new_expression = f\"T{num1}+{num2}={result}\"\n",
    "            \n",
    "            else:\n",
    "                return \"Invalid modify pattern\"\n",
    "        \n",
    "            return new_expression\n",
    "        else:\n",
    "            return \"Invalid expression format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlap_data_path = './data/get_data_with_label/train_3digit_bilabeled10000_nonoverlap.txt'\n",
    "num_examples = 10000\n",
    "new_creator = create_test_data(non_overlap_data_path, num_examples)\n",
    "new_creator.create_prompt()\n",
    "new_creator.create_extra_num_judge_prompt()\n",
    "new_creator.create_add_noise_judge_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.63M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(16, 384)\n",
       "    (wpe): Embedding(256, 384)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=16, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GPTConfig, GPT\n",
    "import torch\n",
    "\n",
    "# init from a model saved in a specific directory\n",
    "ckpt_path = 'ckpt_judge_acc_bilabel(0.2p).pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=mydevice)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta from ./data/addition_bilabel/meta.pkl...\n"
     ]
    }
   ],
   "source": [
    "encode, decode = get_encode_decode('./data/addition_bilabel/meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 21464.04it/s]\n",
      "100%|██████████| 80/80 [00:01<00:00, 58.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 9451/10000 (94.51%)\n",
      "accuracy of 10000 examples: 9451/10000 (94.51%)\n",
      "{'carry0': 96.17253948967192, 'carry1': 92.01692524682652, 'carry2': 95.63205091119468, 'carry3': 96.15384615384616}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94.51,\n",
       " 94.51,\n",
       " {'carry0': 96.17253948967192,\n",
       "  'carry1': 92.01692524682652,\n",
       "  'carry2': 95.63205091119468,\n",
       "  'carry3': 96.15384615384616})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./prompt.txt',\n",
    "    'device': mydevice,\n",
    "    'temperature': 0.8\n",
    "}\n",
    "eval_addition_batch(config, model, ctx, encode, decode, judge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./extra_num_judge_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20338.96it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 246.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 8829/10000 (88.29%)\n",
      "No judging probability of 10000 examples: 0/10000 (0.0%)\n",
      "True Positive Examples: 3487/10000\n",
      "False Positive Examples: 15/10000\n",
      "True Negative Examples: 5342/10000\n",
      "False Negative Examples: 1156/10000\n",
      "{'carry0': 88.63912515188336, 'carry1': 87.67277856135401, 'carry2': 88.05322533989008, 'carry3': 90.08875739644971}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88.29,\n",
       " 0.0,\n",
       " {'carry0': 88.63912515188336,\n",
       "  'carry1': 87.67277856135401,\n",
       "  'carry2': 88.05322533989008,\n",
       "  'carry3': 90.08875739644971})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./extra_num_judge_prompt.txt',\n",
    "    'device': mydevice,\n",
    "}\n",
    "eval_judge_batch(config, model, ctx, encode, decode, max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./add_noise_judge_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 25607.16it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 277.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 6672/10000 (66.72%)\n",
      "No judging probability of 10000 examples: 0/10000 (0.0%)\n",
      "True Positive Examples: 3746/10000\n",
      "False Positive Examples: 2102/10000\n",
      "True Negative Examples: 2926/10000\n",
      "False Negative Examples: 1226/10000\n",
      "{'carry0': 61.05710814094775, 'carry1': 65.8392101551481, 'carry2': 68.03586925079549, 'carry3': 72.55917159763314}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66.72,\n",
       " 0.0,\n",
       " {'carry0': 61.05710814094775,\n",
       "  'carry1': 65.8392101551481,\n",
       "  'carry2': 68.03586925079549,\n",
       "  'carry3': 72.55917159763314})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./add_noise_judge_prompt.txt',\n",
    "    'device': mydevice,\n",
    "}\n",
    "eval_judge_batch(config, model, ctx, encode, decode, max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试一个positive instances对应5个不同的negative instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "class create_test_data:\n",
    "    def __init__(self, non_overlap_data_path, num_test_samples=100) -> None:\n",
    "        if not os.path.exists(non_overlap_data_path):\n",
    "            raise ValueError(\"There is no nonoverlap data file\")\n",
    "        self.non_overlap_data_path = non_overlap_data_path\n",
    "        self.num_test_samples = num_test_samples\n",
    "        self.samples = None\n",
    "        # Open non-overlap data path to get a bunch of test samples\n",
    "        with open(self.non_overlap_data_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            random.shuffle(lines)\n",
    "            self.samples = lines[:self.num_test_samples]\n",
    "            \n",
    "        \n",
    "    def create_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'Ta+b=' .\n",
    "        The output should be correct answer and judgement\n",
    "        \"\"\"\n",
    "        with open(f'prompt.txt', 'w') as f2:\n",
    "            for line in self.samples:\n",
    "                prompt = line.split('=')[0]+'=\\n'\n",
    "                f2.write(prompt)\n",
    "                    \n",
    "    def create_add_noise_judge_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'a+b=c' and 'a+b=d', where 'd' means wrong answer\n",
    "        The output should be judgement\n",
    "        \"\"\"\n",
    "        with open('add_noise_judge_prompt.txt', 'w') as f3:\n",
    "            for line in self.samples:\n",
    "                # 取出表达式部分\n",
    "                prompt = line.split('T')[1].strip()\n",
    "                # prompt = prompt.split('=')[0].strip()\n",
    "                new_prompt = self.modify_result(prompt, random.randint(1, 9), 'noise_add')\n",
    "                f3.write(new_prompt + '?\\n')\n",
    "                \n",
    "    def create_extra_num_judge_prompt(self):\n",
    "        \"\"\"\n",
    "        To create prompt data file like: 'a+b=c' and 'a+b=cd', where 'd' means extra number\n",
    "        The output should be judgement\n",
    "        \"\"\"\n",
    "        with open('extra_num_judge_prompt.txt', 'w') as f4:\n",
    "            for line in self.samples:\n",
    "                # 取出表达式部分\n",
    "                prompt = line.split('T')[1].strip()\n",
    "                # prompt = prompt.split('=')[0].strip()\n",
    "                new_prompt = self.modify_result(prompt, random.randint(1, 9), 'extra_num')\n",
    "                f4.write(new_prompt + '?\\n')\n",
    "\n",
    "    \n",
    "    def modify_result(self, expression, addend, mode):\n",
    "        # 使用正则表达式提取表达式中的数字\n",
    "        match = re.match(r'(\\d+)\\+(\\d+)=(\\d+)', expression)\n",
    "    \n",
    "        if match:\n",
    "            # 提取数字并计算新的结果\n",
    "            num1 = int(match.group(1))\n",
    "            num2 = int(match.group(2))\n",
    "            result = int(match.group(3))\n",
    "            num_digit = len(match.group(3).strip())\n",
    "            if mode == 'extra_num':\n",
    "                if random.uniform(0,1)>0.5 and random.uniform(0,1)<0.75:\n",
    "                    extra = random.randint(1, 9)\n",
    "                    new_expression = f\"F{num1}+{num2}={result}{extra}\"\n",
    "                elif random.uniform(0,1)>0.75:\n",
    "                    extra = random.randint(1, 9)\n",
    "                    new_expression = f\"F{num1}+{num2}={extra}{result}\"\n",
    "                else:\n",
    "                    new_expression = f\"T{num1}+{num2}={result}\"\n",
    "            elif mode == 'noise_add':\n",
    "                if random.uniform(0,1)>0.5:\n",
    "                    # 决定添加错误的位置\n",
    "                    wrong_loc = random.randint(0, num_digit)\n",
    "        \n",
    "                    new_result = result + addend * (10**wrong_loc)\n",
    "\n",
    "                    # 构建新的表达式\n",
    "                    new_expression = f\"F{num1}+{num2}={new_result}\"\n",
    "                else:\n",
    "                    new_expression = f\"T{num1}+{num2}={result}\"\n",
    "            \n",
    "            else:\n",
    "                return \"Invalid modify pattern\"\n",
    "        \n",
    "            return new_expression\n",
    "        else:\n",
    "            return \"Invalid expression format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlap_data_path = './data/get_data_with_label/train_3digit_bilabeled10000_nonoverlap.txt'\n",
    "num_examples = 10000\n",
    "new_creator = create_test_data(non_overlap_data_path, num_examples)\n",
    "new_creator.create_prompt()\n",
    "new_creator.create_extra_num_judge_prompt()\n",
    "new_creator.create_add_noise_judge_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.63M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(16, 384)\n",
       "    (wpe): Embedding(256, 384)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=16, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GPTConfig, GPT\n",
    "import torch\n",
    "\n",
    "# init from a model saved in a specific directory\n",
    "ckpt_path = 'addition-bilabel-5neg-0.7p.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=mydevice)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta from ./data/addition_bilabel_5neg/meta.pkl...\n"
     ]
    }
   ],
   "source": [
    "encode, decode = get_encode_decode('./data/addition_bilabel_5neg/meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 21119.06it/s]\n",
      "100%|██████████| 81/81 [00:01<00:00, 48.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 4689/10000 (46.89%)\n",
      "accuracy of 10000 examples: 9600/10000 (96.0%)\n",
      "{'carry0': 96.74170616113744, 'carry1': 94.65584778959149, 'carry2': 96.94207586004117, 'carry3': 96.2602842183994}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46.89,\n",
       " 96.0,\n",
       " {'carry0': 96.74170616113744,\n",
       "  'carry1': 94.65584778959149,\n",
       "  'carry2': 96.94207586004117,\n",
       "  'carry3': 96.2602842183994})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./prompt.txt',\n",
    "    'device': mydevice,\n",
    "    'temperature': 0.8\n",
    "}\n",
    "eval_addition_batch(config, model, ctx, encode, decode, judge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./extra_num_judge_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 23437.23it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 272.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 8391/10000 (83.91%)\n",
      "No judging probability of 10000 examples: 0/10000 (0.0%)\n",
      "True Positive Examples: 3081/10000\n",
      "False Positive Examples: 10/10000\n",
      "True Negative Examples: 5310/10000\n",
      "False Negative Examples: 1599/10000\n",
      "{'carry0': 85.66350710900474, 'carry1': 83.04420817011751, 'carry2': 83.44604528079977, 'carry3': 85.19072550486163}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(83.91,\n",
       " 0.0,\n",
       " {'carry0': 85.66350710900474,\n",
       "  'carry1': 83.04420817011751,\n",
       "  'carry2': 83.44604528079977,\n",
       "  'carry3': 85.19072550486163})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./extra_num_judge_prompt.txt',\n",
    "    'device': mydevice,\n",
    "}\n",
    "eval_judge_batch(config, model, ctx, encode, decode, max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./add_noise_judge_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 31638.93it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 273.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 6700/10000 (67.0%)\n",
      "No judging probability of 10000 examples: 0/10000 (0.0%)\n",
      "True Positive Examples: 3294/10000\n",
      "False Positive Examples: 1597/10000\n",
      "True Negative Examples: 3406/10000\n",
      "False Negative Examples: 1703/10000\n",
      "{'carry0': 65.3436018957346, 'carry1': 65.5288192501399, 'carry2': 67.59776536312849, 'carry3': 71.50336574420344}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67.0,\n",
       " 0.0,\n",
       " {'carry0': 65.3436018957346,\n",
       "  'carry1': 65.5288192501399,\n",
       "  'carry2': 67.59776536312849,\n",
       "  'carry3': 71.50336574420344})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = nullcontext()\n",
    "config={\n",
    "    'start': 'FILE:./add_noise_judge_prompt.txt',\n",
    "    'device': mydevice,\n",
    "}\n",
    "eval_judge_batch(config, model, ctx, encode, decode, max_new_tokens=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
