{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这个notebook用来测试addition evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 10.63M\n"
     ]
    }
   ],
   "source": [
    "from model import GPTConfig, GPT\n",
    "import torch\n",
    "\n",
    "init_from = 'resume'\n",
    "\n",
    "\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = 'bilabel_ckpt_acc.pt'\n",
    "    checkpoint = torch.load(ckpt_path, map_location='cuda')\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "config={\n",
    "    'start': 'FILE:./data/addition_bilabel/prompt_3digit_10000.txt',\n",
    "    'device': 'cuda',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta from ./data/addition_bilabel/meta.pkl...\n"
     ]
    }
   ],
   "source": [
    "encode, decode = get_encode_decode('./data/addition_bilabel/meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating addition from: FILE:./data/addition_bilabel/prompt_3digit_10000.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:13<00:00, 753.46it/s]\n",
      "100%|██████████| 81/81 [00:04<00:00, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement accuracy of 10000 examples: 9350/10000 (93.5%)\n",
      "accuracy of 10000 examples: 9350/10000 (93.5%)\n",
      "{'carry0': 92.20543806646526, 'carry1': 90.75630252100841, 'carry2': 95.14619883040936, 'carry3': 98.1549815498155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.5,\n",
       " 93.5,\n",
       " {'carry0': 92.20543806646526,\n",
       "  'carry1': 90.75630252100841,\n",
       "  'carry2': 95.14619883040936,\n",
       "  'carry3': 98.1549815498155})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "\n",
    "dtype = 'bfloat16'\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "device_type = 'cuda'\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "eval_addition_batch(config, model, ctx, encode, decode, judge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'213+199=4121F'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '213+199=4121'\n",
    "ids = encode(x)\n",
    "input = (torch.tensor(ids, dtype=torch.long, device='cpu')[None, ...])\n",
    "model.to(device='cpu')\n",
    "output = model.generate(input, max_new_tokens=1)\n",
    "decode(output[0].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
